CV]  5 Aug 2020  Ultra Fast Structure-aware Deep Lane Detection  Zequn Qin, Huanyu Wang, and Xi Li [0000 0003 3023 1662]  College of Computer Science & Technology,  Zhejiang University, Hangzhou, China  zequnqin@gmail.
com/cfzd/Ultra-Fast-Lane-Detection.
  Keywords: Lane detection, Fast formulation, Structural loss, Row anchor  1 Introduction  With a long research history in computer vision, lane detection is a fundamental prob lem and has a wide range of applications [8] (e.
 In this way, Ultra Fast Structure-aware Deep Lane Detection  3  Fig.
â€“ The proposed method achieves the state-of-the-art performance in terms of both  accuracy and speed on the challenging CULane dataset.
 Suppose X is the global image feature and fij is the 5  Ultra Fast Structure-aware Deep Lane Detection  Table 1.
Forexample,using the common settings  of the CULane dataset [22], the ideal computational cost of our method is 17 104  calculations and the one for segmentation is 115 106 calculations.
 6  Lane #1  Z.
  Location of Lane #1  Lane #2  Lane #C  (a) Our formulation  w+1  griding cell  Selecting  along rows  C  h  W  H  formula  formula  Selecting  along channels  C+1  (b) Segmentation  Fig.
  Location of Lane #1  Lane #2  Lane #C  (a) Our formulation  w+1  griding cell  Selecting  along rows  C  h  W  H  formula  formula  Selecting  along channels  C+1  (b) Segmentation  Fig.
  Location of Lane #1  Lane #2  Lane #C  (a) Our formulation  w+1  griding cell  Selecting  along rows  C  h  W  H  formula  formula  Selecting  along channels  C+1  (b) Segmentation  Fig.
2 Lanestructural loss  Besides the classification loss, we further propose two loss functions which aim at mod eling location relations of lane points.
 So the continuous property  is realized by constraining the distribution of classification vectors over adjacent row Ultra Fast Structure-aware Deep Lane Detection  7  anchors.
 4 Experiments  Ultra Fast Structure-aware Deep Lane Detection  9  In this section, we demonstrate the effectiveness of our method with extensive experi ments.
 Datasets description  Dataset #Frame Train Validation Test Resolution #Lane #Scenarios  environment  TuSimple 6,408 3,268  358  2,782 1280 720 5  CULane 133,235 88,880 9,675 34,680 1640 590 4  1  9  highway  urban and highway  4.
 Datasets description  Dataset #Frame Train Validation Test Resolution #Lane #Scenarios  environment  TuSimple 6,408 3,268  358  2,782 1280 720 5  CULane 133,235 88,880 9,675 34,680 1640 590 4  1  9  highway  urban and highway  4.
 To evaluate our approach, we conduct experiments on two widely used bench mark datasets: TuSimple Lane detection benchmark [26] and CULane dataset [22].
 To evaluate our approach, we conduct experiments on two widely used bench mark datasets: TuSimple Lane detection benchmark [26] and CULane dataset [22].
 CULane  dataset consists of nine different scenarios, including normal, crowd, curve, dazzle light,  night, no line, shadow, and arrow in the urban area.
 As for the evaluation metric of CULane, each lane  is treated as a 30-pixel-width line.
 The counterpart of CULane dataset  ranges from 260 to 530, with the same step as Tusimple.
 The image height of CULane  dataset is 540.
 The number of gridding cells is set to 100 on the Tusimple dataset and  150 on the CULane dataset.
 The batch size is  set to 32, and the total number of training epochs is set 100 for TuSimple dataset and 50  for CULane dataset.
959  Ultra Fast Structure-aware Deep Lane Detection  11  1.
3 Results  In this section, we show the results on two lane detection datasets, which are the Tusim ple lane detection benchmark and the CULane dataset.
  For the Tusimple lane detection benchmark, seven methods are used for compari son, including Res18-Seg [3], Res34-Seg [3], LaneNet [21], EL-GAN [5], SCNN [22]  and SAD [9].
 UltraFastStructure-awareDeepLaneDetection 13  FromTable5,wecanseethatourmethodachievescomparableperformancewith  state-of-the-artmethodswhileourmethodcouldrunextremelyfast.
6x  LaneNet[21] 96.
  For theCULanedataset, fourmethods, includingSeg[3],SCNN[22],FastDraw  [24]andSAD[9], areusedforcomparison.
ComparisonofF1-measureandruntimeonCULanetestingsetwithIoUthreshold=0.
 Visualization on the Tusimple and the CULane dataset.
 The first two rows are results on  the Tusimple dataset and the rest rows are results on the CULane dataset.
  The visualizations of our method on the Tusimple and CULane datasets are shown  in Fig.
 References  Ultra Fast Structure-aware Deep Lane Detection  15  1.
: Lane detection using histogram-based segmentation and deci sion trees.
: Lane detection using spline model.
: Lane detection and tracking using b-snake.
: Lane boundary detection using a multi-resolution hough transform.

